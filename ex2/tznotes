
    % Initialize some useful values
    n = length(y); % number of training examples
    
    % cost: J
    J = -1/n * sum(...
        y      .* log(sigmoid(X * theta)) + ...
        (1 - y) .* log(1 - sigmoid(X * theta)) ...
    );

    % gradient: compute as the derivative of the cost function
    grad = 1/n * X' * ((sigmoid(X * theta)) - y);


% htheta = sigmoid(X * theta);
% J = 1 / m * sum(-y .* log(htheta) - (1 - y) .* log(1 - htheta));
% for i = 1:size(theta, 1)
%    grad(i) = 1 / m * sum((htheta - y) .* X(:, i));
% end